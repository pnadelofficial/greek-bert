{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3a6f5d",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9230bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "glaux_dir = Path(\"/cluster/tufts/tuftsai/pnadel01/greek-bert/wsd/glaux/xml\")\n",
    "sentences = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72afccc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1421"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_files = list(glaux_dir.rglob('*.xml'))\n",
    "len(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f5ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_xml(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml-xml')\n",
    "        \n",
    "    root = ET.fromstring(str(soup))\n",
    "    \n",
    "    # Iterate through sentences\n",
    "    for sentence in root.findall('.//sentence'):\n",
    "        sentence_id = sentence.get('id')\n",
    "        document_id = sentence.get('document_id', '')\n",
    "        subdoc = sentence.get('subdoc', '')\n",
    "        \n",
    "        # Create a full GLAUx ID (you may need to adjust this)\n",
    "        # The exact ID format might vary - check your WSD files\n",
    "        glaux_id = sentence_id\n",
    "        if document_id:\n",
    "            glaux_id = f\"{document_id}_{sentence_id}\"\n",
    "        \n",
    "        # Extract words\n",
    "        words = []\n",
    "        lemmas = []\n",
    "        pos_tags = []\n",
    "        \n",
    "        for word in sentence.findall('.//word'):\n",
    "            form = word.get('form', '')\n",
    "            lemma = word.get('lemma', '')\n",
    "            postag = word.get('postag', '')\n",
    "            \n",
    "            if form:\n",
    "                words.append(form)\n",
    "                lemmas.append(lemma)\n",
    "                pos_tags.append(postag)\n",
    "        \n",
    "        # Create sentence text\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        # Store sentence data\n",
    "        sentences[glaux_id] = {\n",
    "            'text': text,\n",
    "            'words': words,\n",
    "            'lemmas': lemmas,\n",
    "            'pos': pos_tags,\n",
    "            'file': str(file_path.name),\n",
    "            'document_id': document_id,\n",
    "            'subdoc': subdoc\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6d5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xml_file in xml_files:\n",
    "    tree = parse_xml(xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a3dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_path = glaux_dir / 'glaux_sentences.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentences, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c388ba",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b9c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class WSDConfig:\n",
    "    \"\"\"Configuration for WSD training\"\"\"\n",
    "    model_name: str = \"/cluster/tufts/tuftsai/pnadel01/greek-bert/hf_format\" \n",
    "    max_length: int = 512\n",
    "    batch_size: int = 16\n",
    "    learning_rate: float = 2e-5\n",
    "    num_epochs: int = 10\n",
    "    warmup_steps: int = 100\n",
    "    weight_decay: float = 0.01\n",
    "    dropout: float = 0.1\n",
    "    test_size: float = 0.2\n",
    "    random_state: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89eb36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "glaux_dir = Path(\"/cluster/tufts/tuftsai/pnadel01/greek-bert/wsd/glaux/xml\")\n",
    "with open(glaux_dir / 'glaux_sentences.json', 'r', encoding='utf-8') as f:\n",
    "    sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f172ca2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'τοὶ γὰρ ἄριστοι μάρτυροι ἔσσονται καὶ ἐπίσκοποι ἁρμονιάων ·',\n",
       " 'words': ['τοὶ',\n",
       "  'γὰρ',\n",
       "  'ἄριστοι',\n",
       "  'μάρτυροι',\n",
       "  'ἔσσονται',\n",
       "  'καὶ',\n",
       "  'ἐπίσκοποι',\n",
       "  'ἁρμονιάων',\n",
       "  '·'],\n",
       " 'lemmas': ['ὁ',\n",
       "  'γάρ',\n",
       "  'ἀγαθός',\n",
       "  'μάρτυς',\n",
       "  'εἰμί',\n",
       "  'καί',\n",
       "  'ἐπίσκοπος',\n",
       "  'ἁρμονία',\n",
       "  '·'],\n",
       " 'pos': ['l-p---mn-',\n",
       "  'g--------',\n",
       "  'a-p---mns',\n",
       "  'n-p---mn-',\n",
       "  'v3pfim---',\n",
       "  'b--------',\n",
       "  'a-p---mn-',\n",
       "  'n-p---fg-',\n",
       "  'u--------'],\n",
       " 'file': '0012-001.xml',\n",
       " 'document_id': '0012-001',\n",
       " 'subdoc': '7716',\n",
       " 'word_ids': ['100117122',\n",
       "  '100117123',\n",
       "  '100117124',\n",
       "  '100117125',\n",
       "  '100117126',\n",
       "  '100117127',\n",
       "  '100117128',\n",
       "  '100117129',\n",
       "  '100117130']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glaux_id2word_id = {}\n",
    "for glaux_id, sent_data in sentences.items():\n",
    "    word_ids = sent_data['word_ids']\n",
    "    for word_id in word_ids:\n",
    "        glaux_id2word_id[word_id] = glaux_id\n",
    "\n",
    "glaux_id2word_id['100117129']\n",
    "sentences['0012-001_7306']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6ebdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glaux_dir / 'glaux_id2word_id.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(glaux_id2word_id, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184dec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class WSDDataset(Dataset):\n",
    "    def __init__(self, data_path, glaux_data, tokenizer, target_word, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.target_word = target_word\n",
    "        self.max_length = max_length\n",
    "\n",
    "        df = pd.read_csv(data_path, sep=\"\\t\", header=None)\n",
    "\n",
    "        if len(df.columns) == 2:\n",
    "            df.columns = ['glaux_id', 'sense']\n",
    "        else:\n",
    "            df.columns = ['glaux_id', 'sense', 'subsense']\n",
    "\n",
    "        self.data = []\n",
    "        missing_ids = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            word_id = str(row[\"glaux_id\"])\n",
    "            glaux_id = glaux_id2word_id.get(word_id, None)\n",
    "            sense = row[\"sense\"]\n",
    "\n",
    "            if glaux_id in glaux_data:\n",
    "                sentense = glaux_data[glaux_id]\n",
    "                self.data.append({\n",
    "                    'glaux_id': glaux_id,\n",
    "                    'text': sentense['text'],\n",
    "                    'sense': sense,\n",
    "                    'target_position': sentense['word_ids'].index(word_id)\n",
    "                })\n",
    "            else:\n",
    "                missing_ids.append(glaux_id)\n",
    "        \n",
    "        if missing_ids:\n",
    "            print(f\"Warning: {len(missing_ids)} glaux_ids not found in glaux data.\")\n",
    "        print(f\"Loaded {len(self.data)} examples for target word '{self.target_word}'.\")\n",
    "\n",
    "        self.sense_to_id = {sense: idx for idx, sense in enumerate(sorted(set(df['sense'])))}\n",
    "        self.id_to_sense = {idx: sense for sense, idx in self.sense_to_id.items()}\n",
    "        self.num_senses = len(self.sense_to_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        sentence = item['text']\n",
    "        sense_label = self.sense_to_id[item['sense']]\n",
    "        target_position = item['target_position']\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'target_position': target_position,\n",
    "            'label': torch.tensor(sense_label, dtype=torch.long),\n",
    "            'glaux_id': item['glaux_id']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7ea5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /cluster/tufts/tuftsai/pnadel01/greek-bert/hf_format and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "config = WSDConfig()\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "model = AutoModel.from_pretrained(config.model_name).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785f0b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 14 glaux_ids not found in glaux data.\n",
      "Loaded 538 examples for target word 'ἁρμονιά'.\n"
     ]
    }
   ],
   "source": [
    "ds = WSDDataset(\n",
    "    data_path='/cluster/tufts/tuftsai/pnadel01/greek-bert/wsd/ancient-greek-wsd-data/harmonia_glaux.txt',\n",
    "    tokenizer=tokenizer,\n",
    "    glaux_data=sentences,\n",
    "    target_word='ἁρμονιά',\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eeafe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int((1 - config.test_size) * len(ds))\n",
    "val_size = len(ds) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    ds,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(config.random_state)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for debugging, increase for speed\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a4bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WSDClassifier(nn.Module):    \n",
    "    def __init__(self, bert_model, num_senses: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_senses)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, target_position):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        batch_size = sequence_output.size(0)\n",
    "        \n",
    "        target_embeddings = sequence_output[\n",
    "            torch.arange(batch_size, device=sequence_output.device),\n",
    "            target_position\n",
    "        ]  # [batch_size, hidden_size]\n",
    "        \n",
    "        target_embeddings = self.dropout(target_embeddings)\n",
    "        logits = self.classifier(target_embeddings)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cfbefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_classifier = WSDClassifier(bert_model=model, num_senses=ds.num_senses, dropout=config.dropout)\n",
    "wsd_classifier = wsd_classifier.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab639917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    attention_mask = batch['attention_mask'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    target_positions = batch['target_position'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    labels = batch['label'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    logits = wsd_classifier(input_ids, attention_mask, target_positions)\n",
    "\n",
    "    print(logits.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8992c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "\n",
    "        total_steps = len(train_loader) * config.num_epochs\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=config.warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.best_val_acc = 0.0\n",
    "        self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            attention_mask = batch['attention_mask'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            target_positions = batch['target_position'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            labels = batch['label'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(input_ids, attention_mask, target_positions)\n",
    "            loss = self.criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{correct/total:.4f}'\n",
    "            })\n",
    "\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc='Evaluating')\n",
    "            for batch in pbar:\n",
    "                input_ids = batch['input_ids'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                attention_mask = batch['attention_mask'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                target_positions = batch['target_position'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                labels = batch['label'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "                logits = self.model(input_ids, attention_mask, target_positions)\n",
    "                loss = self.criterion(logits, labels)\n",
    "\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{correct/total:.4f}'\n",
    "                })\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "    def train(self, save_dir=\"./wsd_model\"):\n",
    "        save_path = Path(save_dir)\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for epoch in range(1, self.config.num_epochs + 1):\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}\")\n",
    "\n",
    "            val_loss, val_acc, val_preds, val_labels = self.evaluate()\n",
    "            print(f\"Epoch {epoch}: Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'config': self.config\n",
    "                }, save_path / 'best_model.pt')\n",
    "                print(f\"Saved best model with Val Acc={val_acc:.4f} at epoch {epoch}.\")\n",
    "            \n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'config': self.config,\n",
    "            'history': self.history\n",
    "        }, save_path / 'final_model.pt')\n",
    "\n",
    "        with open(save_path / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "\n",
    "        print(\"Training complete. Best Val Acc: {:.4f}\".format(self.best_val_acc))\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c76522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  4.66it/s, loss=1.0059, acc=0.3163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.2122, Train Acc=0.3163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.04it/s, loss=1.3049, acc=0.3704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss=1.0620, Val Acc=0.3704\n",
      "Saved best model with Val Acc=0.3704 at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.39it/s, loss=0.9814, acc=0.5116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.9137, Train Acc=0.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.16it/s, loss=1.1166, acc=0.4537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss=0.8579, Val Acc=0.4537\n",
      "Saved best model with Val Acc=0.4537 at epoch 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.38it/s, loss=0.7336, acc=0.6256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.7891, Train Acc=0.6256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.06it/s, loss=1.0189, acc=0.5556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss=0.8207, Val Acc=0.5556\n",
      "Saved best model with Val Acc=0.5556 at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.38it/s, loss=0.3729, acc=0.8093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.5757, Train Acc=0.8093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.77it/s, loss=0.9308, acc=0.7037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss=0.6801, Val Acc=0.7037\n",
      "Saved best model with Val Acc=0.7037 at epoch 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.30it/s, loss=0.5809, acc=0.9070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.3331, Train Acc=0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.67it/s, loss=0.8580, acc=0.7407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss=0.5875, Val Acc=0.7407\n",
      "Saved best model with Val Acc=0.7407 at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.30it/s, loss=0.1285, acc=0.9605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1783, Train Acc=0.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.70it/s, loss=0.6224, acc=0.8148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Val Loss=0.4595, Val Acc=0.8148\n",
      "Saved best model with Val Acc=0.8148 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.37it/s, loss=0.1115, acc=0.9907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0821, Train Acc=0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.03it/s, loss=0.6325, acc=0.8056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Val Loss=0.4925, Val Acc=0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.35it/s, loss=0.0688, acc=0.9953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0452, Train Acc=0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.82it/s, loss=0.6320, acc=0.8056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Val Loss=0.5456, Val Acc=0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.33it/s, loss=0.0104, acc=0.9953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0271, Train Acc=0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.76it/s, loss=0.6488, acc=0.8241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Val Loss=0.5510, Val Acc=0.8241\n",
      "Saved best model with Val Acc=0.8241 at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.33it/s, loss=0.0122, acc=0.9977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0188, Train Acc=0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.84it/s, loss=0.6841, acc=0.8148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Val Loss=0.5798, Val Acc=0.8148\n",
      "Training complete. Best Val Acc: 0.8241\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(wsd_classifier, train_loader, val_loader, config)\n",
    "history = trainer.train(save_dir=\"./wsd_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a7ff1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Jacobo/aristoBERTo and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ari_config = WSDConfig(model_name=\"Jacobo/aristoBERTo\")\n",
    "ari_tokenizer = AutoTokenizer.from_pretrained(ari_config.model_name)\n",
    "ari_model = AutoModel.from_pretrained(ari_config.model_name).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6191948",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_wsd_classifier = WSDClassifier(bert_model=ari_model, num_senses=ds.num_senses, dropout=ari_config.dropout)\n",
    "ari_wsd_classifier = ari_wsd_classifier.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7bc2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.38it/s, loss=1.0686, acc=0.4209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.0208, Train Acc=0.4209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.03it/s, loss=0.7826, acc=0.5000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss=0.9187, Val Acc=0.5000\n",
      "Saved best model with Val Acc=0.5000 at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.40it/s, loss=0.8848, acc=0.4512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.9413, Train Acc=0.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.19it/s, loss=0.8487, acc=0.4722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss=0.8728, Val Acc=0.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.39it/s, loss=0.9569, acc=0.5767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.8256, Train Acc=0.5767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.93it/s, loss=0.7905, acc=0.5278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss=0.8194, Val Acc=0.5278\n",
      "Saved best model with Val Acc=0.5278 at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.37it/s, loss=0.5684, acc=0.7047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.6891, Train Acc=0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 15.10it/s, loss=0.8290, acc=0.5093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss=0.8125, Val Acc=0.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.35it/s, loss=0.3994, acc=0.8605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.4999, Train Acc=0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.94it/s, loss=0.5971, acc=0.6759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss=0.7001, Val Acc=0.6759\n",
      "Saved best model with Val Acc=0.6759 at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.36it/s, loss=0.3193, acc=0.9535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.3405, Train Acc=0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.83it/s, loss=0.6933, acc=0.6481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Val Loss=0.6553, Val Acc=0.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.32it/s, loss=0.1584, acc=0.9721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.2092, Train Acc=0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.81it/s, loss=0.6292, acc=0.7315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Val Loss=0.5636, Val Acc=0.7315\n",
      "Saved best model with Val Acc=0.7315 at epoch 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.31it/s, loss=0.1061, acc=0.9791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1408, Train Acc=0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.69it/s, loss=0.7203, acc=0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Val Loss=0.5468, Val Acc=0.7500\n",
      "Saved best model with Val Acc=0.7500 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.31it/s, loss=0.0494, acc=0.9953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0990, Train Acc=0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.55it/s, loss=0.6530, acc=0.7593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Val Loss=0.5021, Val Acc=0.7593\n",
      "Saved best model with Val Acc=0.7593 at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:05<00:00,  5.32it/s, loss=0.0419, acc=0.9930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0742, Train Acc=0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 14.81it/s, loss=0.6573, acc=0.7870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Val Loss=0.4881, Val Acc=0.7870\n",
      "Saved best model with Val Acc=0.7870 at epoch 10.\n",
      "Training complete. Best Val Acc: 0.7870\n"
     ]
    }
   ],
   "source": [
    "ari_trainer = Trainer(ari_wsd_classifier, train_loader, val_loader, ari_config)\n",
    "history = ari_trainer.train(save_dir=\"./ari_wsd_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c9f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_purpose_textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
